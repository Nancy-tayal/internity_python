{
 "cells": [
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "26b2fc09",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "* Logistic regression is one of the most popular Machine learning algorithm that comes under Supervised Learning techniques.\n",
    "* It can be used for Classification as well as for Regression problems, but mainly used for Classification problems.\n",
    "* Logistic regression is used to predict the categorical dependent variable with the help of independent variables.\n",
    "* The output of Logistic Regression problem can be only between the 0 and 1.\n",
    "* Logistic regression can be used where the probabilities between two classes is required. Such as whether it will rain today or not, either 0 or 1, true or false etc.\n",
    "* Logistic regression is based on the concept of Maximum Likelihood estimation. According to this estimation, the observed data should be most probable.\n",
    "* In logistic regression, we pass the weighted sum of inputs through an activation function that can map values in between 0 and 1. Such activation function is known as sigmoid function and the curve obtained is called as sigmoid curve or S-curve. Consider the below image:\n",
    "![image.png](attachment:image.png)\n",
    "The equation for logistic regression is:\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "**Logistic Function (Sigmoid Function):**\n",
    "* The sigmoid function is a mathematical function used to map the predicted values to probabilities.\n",
    "* It maps any real value into another value within a range of 0 and 1.\n",
    "* The value of the logistic regression must be between 0 and 1, which cannot go beyond this limit, so it forms a curve like the \"S\" form. The S-form curve is called the Sigmoid function or the logistic function.\n",
    "* In logistic regression, we use the concept of the threshold value, which defines the probability of either 0 or 1. Such as values above the threshold value tends to 1, and a value below the threshold values tends to 0.\n",
    "\n",
    "**Assumptions for Logistic Regression:**\n",
    "* The dependent variable must be categorical in nature.\n",
    "* The independent variable should not have multi-collinearity.\n",
    "\n",
    "**Linear Regression V/S Logistic Regression**\n",
    "* Linear regression is used to predict the continuous dependent variable using a given set of independent variables.\tLogistic Regression is used to predict the categorical dependent variable using a given set of independent variables.\n",
    "* Linear Regression is used for solving Regression problem.\tLogistic regression is used for solving Classification problems.\n",
    "* In Linear regression, we predict the value of continuous variables.\tIn logistic Regression, we predict the values of categorical variables.\n",
    "* In linear regression, we find the best fit line, by which we can easily predict the output.\tIn Logistic Regression, we find the S-curve by which we can classify the samples.\n",
    "* Least square estimation method is used for estimation of accuracy.\tMaximum likelihood estimation method is used for estimation of accuracy.\n",
    "* The output for Linear Regression must be a continuous value, such as price, age, etc.\tThe output of Logistic Regression must be a Categorical value such as 0 or 1, Yes or No, etc.\n",
    "* In Linear regression, it is required that relationship between dependent variable and independent variable must be linear.\t* In Logistic regression, it is not required to have the linear relationship between the dependent and independent variable.\n",
    "* In linear regression, there may be collinearity between the independent variables.\tIn logistic regression, there should not be collinearity between the independent variable.\n",
    "\n",
    "**The three types of logistic regression are:**\n",
    "\n",
    "* Binary logistic regression is the statistical technique used to predict the relationship between the dependent variable (Y) and the independent variable (X), where the dependent variable is binary in nature. For example, the output can be Success/Failure,  0/1 , True/False, or Yes/No. This is the type of logistic regression that we’ve been focusing on in this post.\n",
    "* Multinomial logistic regression is used when you have one categorical dependent variable with two or more unordered levels (i.e two or more discrete outcomes). It is very similar to logistic regression except that here you can have more than two possible outcomes. For example, let’s imagine that you want to predict what will be the most-used transportation type in the year 2030. The transport type will be the dependent variable, with possible outputs of train, bus, tram, and bike (for example).\n",
    "* Ordinal logistic regression is used when the dependent variable (Y) is ordered (i.e., ordinal). The dependent variable has a meaningful order and more than two categories or levels. Examples of such variables might be t-shirt size (XS/S/M/L/XL), answers on an opinion poll (Agree/Disagree/Neutral), or scores on a test (Poor/Average/Good).\n",
    "\n",
    "**Applications of Logistic Regression**\n",
    "\n",
    "* Weather prediction (only for predicting the categorical data)\n",
    "* Determining illness (if illness is positive or negative)\n",
    "* Tumour prediction (to identify if a tumour is malignant or benign)\n",
    "* Classify email is spam or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4ed4f",
   "metadata": {},
   "source": [
    "# Binomial Logistic Regression Use Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "08660150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "cancer = load_breast_cancer()\n",
    "print(cancer.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "94dc2723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "print(cancer.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f58bcae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ca5e7647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "52ea9220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "122d4b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1       2       3        4        5        6        7       8  \\\n",
       "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
       "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
       "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
       "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
       "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
       "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
       "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
       "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
       "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
       "568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n",
       "\n",
       "           9  ...     21      22      23       24       25      26      27  \\\n",
       "0    0.07871  ...  17.33  184.60  2019.0  0.16220  0.66560  0.7119  0.2654   \n",
       "1    0.05667  ...  23.41  158.80  1956.0  0.12380  0.18660  0.2416  0.1860   \n",
       "2    0.05999  ...  25.53  152.50  1709.0  0.14440  0.42450  0.4504  0.2430   \n",
       "3    0.09744  ...  26.50   98.87   567.7  0.20980  0.86630  0.6869  0.2575   \n",
       "4    0.05883  ...  16.67  152.20  1575.0  0.13740  0.20500  0.4000  0.1625   \n",
       "..       ...  ...    ...     ...     ...      ...      ...     ...     ...   \n",
       "564  0.05623  ...  26.40  166.10  2027.0  0.14100  0.21130  0.4107  0.2216   \n",
       "565  0.05533  ...  38.25  155.00  1731.0  0.11660  0.19220  0.3215  0.1628   \n",
       "566  0.05648  ...  34.12  126.70  1124.0  0.11390  0.30940  0.3403  0.1418   \n",
       "567  0.07016  ...  39.42  184.60  1821.0  0.16500  0.86810  0.9387  0.2650   \n",
       "568  0.05884  ...  30.37   59.16   268.6  0.08996  0.06444  0.0000  0.0000   \n",
       "\n",
       "         28       29  Target  \n",
       "0    0.4601  0.11890       0  \n",
       "1    0.2750  0.08902       0  \n",
       "2    0.3613  0.08758       0  \n",
       "3    0.6638  0.17300       0  \n",
       "4    0.2364  0.07678       0  \n",
       "..      ...      ...     ...  \n",
       "564  0.2060  0.07115       0  \n",
       "565  0.2572  0.06637       0  \n",
       "566  0.2218  0.07820       0  \n",
       "567  0.4087  0.12400       0  \n",
       "568  0.2871  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame(cancer.data)\n",
    "df[\"Target\"]= cancer.target\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "40f93033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n"
     ]
    }
   ],
   "source": [
    "x=df.drop([\"Target\"], axis=1)\n",
    "y= df[\"Target\"]\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d025f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2c4ecc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 30)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "53f1a3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "340c4c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "st_x= StandardScaler()    \n",
    "x_train= st_x.fit_transform(x_train)    \n",
    "x_test= st_x.transform(x_test)  \n",
    "clf= LogisticRegression(random_state=0)  \n",
    "clf.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d2e34814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.94      0.94      0.94        53\\n           1       0.97      0.97      0.97        90\\n\\n    accuracy                           0.96       143\\n   macro avg       0.96      0.96      0.96       143\\nweighted avg       0.96      0.96      0.96       143\\n'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(x_test)\n",
    "classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4fc0d3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  3]\n",
      " [ 3 87]]\n",
      "0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "36ea8f7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.98638613e-01 1.36138656e-03]\n",
      " [3.95544804e-02 9.60445520e-01]\n",
      " [1.30896362e-03 9.98691036e-01]\n",
      " [1.24473354e-02 9.87552665e-01]\n",
      " [2.44132101e-04 9.99755868e-01]\n",
      " [4.50491513e-03 9.95495085e-01]\n",
      " [1.13985968e-04 9.99886014e-01]\n",
      " [1.82475894e-03 9.98175241e-01]\n",
      " [9.67965506e-05 9.99903203e-01]\n",
      " [1.75222878e-06 9.99998248e-01]\n",
      " [1.76572612e-01 8.23427388e-01]\n",
      " [8.24119135e-02 9.17588087e-01]\n",
      " [9.66067493e-06 9.99990339e-01]\n",
      " [5.39343196e-01 4.60656804e-01]\n",
      " [3.98187854e-01 6.01812146e-01]\n",
      " [9.95762760e-01 4.23724017e-03]\n",
      " [2.75612083e-03 9.97243879e-01]\n",
      " [9.99997097e-01 2.90271401e-06]\n",
      " [9.99926506e-01 7.34935682e-05]\n",
      " [9.99999997e-01 2.78313939e-09]\n",
      " [9.98738365e-01 1.26163489e-03]\n",
      " [9.81405399e-01 1.85946008e-02]\n",
      " [1.77902039e-02 9.82209796e-01]\n",
      " [9.65876713e-04 9.99034123e-01]\n",
      " [9.99464578e-01 5.35421808e-04]\n",
      " [6.73385015e-04 9.99326615e-01]\n",
      " [5.50833875e-05 9.99944917e-01]\n",
      " [9.69828919e-01 3.01710813e-02]\n",
      " [1.62119075e-03 9.98378809e-01]\n",
      " [9.99997821e-01 2.17867101e-06]\n",
      " [6.00571253e-05 9.99939943e-01]\n",
      " [9.99954808e-01 4.51921300e-05]\n",
      " [1.09252006e-01 8.90747994e-01]\n",
      " [9.97255978e-01 2.74402243e-03]\n",
      " [4.51047979e-06 9.99995490e-01]\n",
      " [9.97449456e-01 2.55054412e-03]\n",
      " [1.97830173e-02 9.80216983e-01]\n",
      " [9.99571529e-01 4.28470822e-04]\n",
      " [8.45566258e-03 9.91544337e-01]\n",
      " [9.99487912e-01 5.12087502e-04]\n",
      " [9.42409583e-01 5.75904174e-02]\n",
      " [8.34700429e-05 9.99916530e-01]\n",
      " [9.32505814e-01 6.74941855e-02]\n",
      " [8.11944408e-05 9.99918806e-01]\n",
      " [6.08911689e-02 9.39108831e-01]\n",
      " [9.99999999e-01 1.17373572e-09]\n",
      " [1.00967748e-06 9.99998990e-01]\n",
      " [1.48182234e-02 9.85181777e-01]\n",
      " [6.33630458e-04 9.99366370e-01]\n",
      " [9.99927519e-01 7.24813084e-05]\n",
      " [9.99989528e-01 1.04724511e-05]\n",
      " [8.04262948e-01 1.95737052e-01]\n",
      " [9.99965014e-01 3.49860375e-05]\n",
      " [1.36691079e-03 9.98633089e-01]\n",
      " [1.95330244e-03 9.98046698e-01]\n",
      " [5.74609838e-04 9.99425390e-01]\n",
      " [1.05063052e-03 9.98949369e-01]\n",
      " [7.96089471e-03 9.92039105e-01]\n",
      " [1.00288029e-02 9.89971197e-01]\n",
      " [9.99999999e-01 1.44073341e-09]\n",
      " [9.97609027e-01 2.39097260e-03]\n",
      " [9.99257870e-01 7.42129950e-04]\n",
      " [3.14309030e-05 9.99968569e-01]\n",
      " [4.40044150e-03 9.95599559e-01]\n",
      " [9.99897373e-01 1.02627439e-04]\n",
      " [1.52976144e-01 8.47023856e-01]\n",
      " [1.00000000e+00 2.39185116e-13]\n",
      " [9.99998777e-01 1.22317020e-06]\n",
      " [9.99999046e-01 9.53579837e-07]\n",
      " [7.96239235e-04 9.99203761e-01]\n",
      " [3.87033734e-01 6.12966266e-01]\n",
      " [9.99993469e-01 6.53125942e-06]\n",
      " [2.97085842e-03 9.97029142e-01]\n",
      " [8.09412134e-01 1.90587866e-01]\n",
      " [9.99996998e-01 3.00240009e-06]\n",
      " [1.75950117e-02 9.82404988e-01]\n",
      " [4.94325863e-05 9.99950567e-01]\n",
      " [3.51047770e-02 9.64895223e-01]\n",
      " [4.25841119e-04 9.99574159e-01]\n",
      " [2.09232609e-05 9.99979077e-01]\n",
      " [9.82374564e-01 1.76254356e-02]\n",
      " [1.00000000e+00 3.57855006e-10]\n",
      " [9.99988747e-01 1.12526453e-05]\n",
      " [5.94724730e-05 9.99940528e-01]\n",
      " [9.62731634e-01 3.72683662e-02]\n",
      " [1.69452548e-03 9.98305475e-01]\n",
      " [6.14966533e-05 9.99938503e-01]\n",
      " [6.36886875e-06 9.99993631e-01]\n",
      " [9.99902779e-01 9.72205364e-05]\n",
      " [1.00000000e+00 8.14423797e-11]\n",
      " [3.47458432e-05 9.99965254e-01]\n",
      " [5.53589378e-01 4.46410622e-01]\n",
      " [6.91462937e-01 3.08537063e-01]\n",
      " [9.99996851e-01 3.14924112e-06]\n",
      " [2.01951834e-03 9.97980482e-01]\n",
      " [2.39759190e-03 9.97602408e-01]\n",
      " [9.99999992e-01 7.92006333e-09]\n",
      " [1.03400237e-02 9.89659976e-01]\n",
      " [9.23218910e-03 9.90767811e-01]\n",
      " [9.80048490e-04 9.99019952e-01]\n",
      " [5.45753731e-09 9.99999995e-01]\n",
      " [3.09034901e-03 9.96909651e-01]\n",
      " [6.22819445e-03 9.93771806e-01]\n",
      " [1.49494565e-01 8.50505435e-01]\n",
      " [9.99994787e-01 5.21292981e-06]\n",
      " [6.02188244e-04 9.99397812e-01]\n",
      " [9.99995658e-01 4.34219020e-06]\n",
      " [9.49795077e-02 9.05020492e-01]\n",
      " [3.27428663e-01 6.72571337e-01]\n",
      " [1.72350019e-02 9.82764998e-01]\n",
      " [3.75686888e-02 9.62431311e-01]\n",
      " [9.99975711e-01 2.42887910e-05]\n",
      " [9.99911399e-01 8.86014791e-05]\n",
      " [8.65663331e-02 9.13433667e-01]\n",
      " [8.21398481e-04 9.99178602e-01]\n",
      " [2.45946373e-02 9.75405363e-01]\n",
      " [1.43898490e-01 8.56101510e-01]\n",
      " [1.58128486e-03 9.98418715e-01]\n",
      " [1.79682971e-02 9.82031703e-01]\n",
      " [1.18803803e-03 9.98811962e-01]\n",
      " [1.55728346e-02 9.84427165e-01]\n",
      " [1.43822197e-03 9.98561778e-01]\n",
      " [3.86829219e-01 6.13170781e-01]\n",
      " [2.65232841e-02 9.73476716e-01]\n",
      " [9.99999918e-01 8.17382381e-08]\n",
      " [1.28424726e-01 8.71575274e-01]\n",
      " [4.67709202e-01 5.32290798e-01]\n",
      " [2.58725940e-04 9.99741274e-01]\n",
      " [3.25269018e-05 9.99967473e-01]\n",
      " [4.00075207e-05 9.99959992e-01]\n",
      " [9.99901036e-01 9.89636008e-05]\n",
      " [1.27248974e-04 9.99872751e-01]\n",
      " [2.66411581e-04 9.99733588e-01]\n",
      " [2.13163719e-01 7.86836281e-01]\n",
      " [2.92511631e-02 9.70748837e-01]\n",
      " [2.37309476e-05 9.99976269e-01]\n",
      " [5.09465728e-01 4.90534272e-01]\n",
      " [6.17881971e-01 3.82118029e-01]\n",
      " [1.00000000e+00 1.46648090e-12]\n",
      " [8.41453252e-05 9.99915855e-01]\n",
      " [1.58701592e-03 9.98412984e-01]\n",
      " [1.26424968e-03 9.98735750e-01]\n",
      " [9.99999994e-01 5.81805301e-09]]\n"
     ]
    }
   ],
   "source": [
    "pre=clf.predict_proba(x_test)\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a334e4",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression Use Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "18eef9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "digits = load_digits()\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3c48644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "print(digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5c706cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
     ]
    }
   ],
   "source": [
    "print(digits.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c9358c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(digits.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "198f36e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fa389b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1     2     3     4     5    6    7    8    9  ...   55   56  \\\n",
       "0     0.0  0.0   5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1     0.0  0.0   0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2     0.0  0.0   0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3     0.0  0.0   7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  0.0  0.0   \n",
       "4     0.0  0.0   0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...   ...  ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1792  0.0  0.0   4.0  10.0  13.0   6.0  0.0  0.0  0.0  1.0  ...  0.0  0.0   \n",
       "1793  0.0  0.0   6.0  16.0  13.0  11.0  1.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1794  0.0  0.0   1.0  11.0  15.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1795  0.0  0.0   2.0  10.0   7.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1796  0.0  0.0  10.0  14.0   8.0   1.0  0.0  0.0  0.0  2.0  ...  0.0  0.0   \n",
       "\n",
       "       57   58    59    60    61   62   63  Target  \n",
       "0     0.0  6.0  13.0  10.0   0.0  0.0  0.0       0  \n",
       "1     0.0  0.0  11.0  16.0  10.0  0.0  0.0       1  \n",
       "2     0.0  0.0   3.0  11.0  16.0  9.0  0.0       2  \n",
       "3     0.0  7.0  13.0  13.0   9.0  0.0  0.0       3  \n",
       "4     0.0  0.0   2.0  16.0   4.0  0.0  0.0       4  \n",
       "...   ...  ...   ...   ...   ...  ...  ...     ...  \n",
       "1792  0.0  2.0  14.0  15.0   9.0  0.0  0.0       9  \n",
       "1793  0.0  6.0  16.0  14.0   6.0  0.0  0.0       0  \n",
       "1794  0.0  2.0   9.0  13.0   6.0  0.0  0.0       8  \n",
       "1795  0.0  5.0  12.0  16.0  12.0  0.0  0.0       9  \n",
       "1796  1.0  8.0  12.0  14.0  12.0  1.0  0.0       8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame(digits.data)\n",
    "df[\"Target\"]= digits.target\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "12ad7a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 64)\n"
     ]
    }
   ],
   "source": [
    "x=df.drop([\"Target\"], axis=1)\n",
    "y= df[\"Target\"]\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2a16ccbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d90f7322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 64)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c09bc866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9eedb2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "st_x= StandardScaler()    \n",
    "x_train= st_x.fit_transform(x_train)    \n",
    "x_test= st_x.transform(x_test)  \n",
    "clf= LogisticRegression(random_state=0)  \n",
    "clf.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "08219000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00        37\\n           1       0.91      0.93      0.92        43\\n           2       0.98      0.98      0.98        44\\n           3       0.98      0.98      0.98        45\\n           4       0.97      0.97      0.97        38\\n           5       0.98      0.96      0.97        48\\n           6       1.00      0.98      0.99        52\\n           7       0.98      0.98      0.98        48\\n           8       0.94      0.92      0.93        48\\n           9       0.94      0.98      0.96        47\\n\\n    accuracy                           0.97       450\\n   macro avg       0.97      0.97      0.97       450\\nweighted avg       0.97      0.97      0.97       450\\n'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(x_test)\n",
    "classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e81a48ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 40  0  0  0  0  0  0  2  1]\n",
      " [ 0  0 43  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 44  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 37  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 46  0  0  0  2]\n",
      " [ 0  1  0  0  0  0 51  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 47  0  0]\n",
      " [ 0  3  1  0  0  0  0  0 44  0]\n",
      " [ 0  0  0  0  0  1  0  0  0 46]]\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "82e43c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.56854026e-07 1.69463660e-06 9.99978689e-01 ... 9.85211801e-06\n",
      "  7.09087241e-07 3.05229709e-07]\n",
      " [8.33589066e-05 6.20780698e-04 6.49621452e-03 ... 1.39283281e-05\n",
      "  8.81371640e-01 4.35007930e-04]\n",
      " [1.06709731e-10 6.71864475e-07 9.99995900e-01 ... 1.39591986e-08\n",
      "  2.70168390e-08 7.27901798e-10]\n",
      " ...\n",
      " [8.77797050e-06 3.17881748e-07 1.74127168e-08 ... 7.07594825e-08\n",
      "  6.37835711e-06 1.23090322e-04]\n",
      " [1.47455183e-06 8.62322159e-01 2.93277547e-04 ... 1.11617478e-05\n",
      "  9.16170921e-02 6.64200853e-06]\n",
      " [4.49491767e-05 1.05264578e-08 2.25315283e-07 ... 1.82821541e-06\n",
      "  6.19335265e-05 9.98775909e-01]]\n"
     ]
    }
   ],
   "source": [
    "pre=clf.predict_proba(x_test)\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e37b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
